#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è·¨æ•°æ®é›†éªŒè¯è„šæœ¬
ç”¨MESAè®­ç»ƒçš„AttnSleepæ¨¡å‹åœ¨CFSæ•°æ®é›†ä¸Šæµ‹è¯•

è¿™ç§æ–¹å¼å¯ä»¥éªŒè¯æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ï¼Œæ˜¯è¯„ä¼°æ¨¡å‹é²æ£’æ€§çš„é‡è¦æŒ‡æ ‡ã€‚

ä½¿ç”¨æ–¹æ³•:
    python cross_dataset_evaluation.py \
        --model_path ./mesa_results/best_mesa_4class_corrected_model.pth \
        --cfs_data_dir ./cfs_eeg_c3m2_data
"""

import os
import numpy as np
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from sklearn.metrics import (
    classification_report, confusion_matrix, 
    accuracy_score, cohen_kappa_score, f1_score
)
import json
import glob
from pathlib import Path
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm import tqdm
import warnings
import argparse
from datetime import datetime

warnings.filterwarnings('ignore')

# å¯¼å…¥æ¨¡å‹ç»„ä»¶
from model import MRCNN, TCE, EncoderLayer, MultiHeadedAttention, PositionwiseFeedForward
from copy import deepcopy


# ============================================================================
# 1. AttnSleep 4ç±»åˆ«æ¨¡å‹ (ä¸MESAè®­ç»ƒæ—¶å®Œå…¨ä¸€è‡´)
# ============================================================================

class AttnSleep4Class(nn.Module):
    """4ç±»åˆ«ç‰ˆæœ¬çš„AttnSleepæ¨¡å‹"""

    def __init__(self):
        super(AttnSleep4Class, self).__init__()

        N = 2
        d_model = 80
        d_ff = 120
        h = 5
        dropout = 0.1
        num_classes = 4
        afr_reduced_cnn_size = 30

        self.mrcnn = MRCNN(afr_reduced_cnn_size)

        attn = MultiHeadedAttention(h, d_model, afr_reduced_cnn_size)
        ff = PositionwiseFeedForward(d_model, d_ff, dropout)
        self.tce = TCE(EncoderLayer(d_model, deepcopy(attn), deepcopy(ff), afr_reduced_cnn_size, dropout), N)

        self.fc = nn.Linear(d_model * afr_reduced_cnn_size, num_classes)

    def forward(self, x):
        x_feat = self.mrcnn(x)
        encoded_features = self.tce(x_feat)
        encoded_features = encoded_features.contiguous().view(encoded_features.shape[0], -1)
        final_output = self.fc(encoded_features)
        return final_output


# ============================================================================
# 2. CFS EEGæ•°æ®é›† (ç”¨äºæµ‹è¯•)
# ============================================================================

class CFSEEGTestDataset(Dataset):
    """
    CFS EEGæµ‹è¯•æ•°æ®é›†
    5ç±»æ ‡ç­¾è½¬æ¢ä¸º4ç±»ä»¥åŒ¹é…MESAæ¨¡å‹
    """

    def __init__(self, npz_files, verbose=True):
        if verbose:
            print(f"ğŸ”§ åŠ è½½ {len(npz_files)} ä¸ªCFS EEGæ–‡ä»¶ç”¨äºæµ‹è¯•...")

        # CFSæ ‡ç­¾æ˜ å°„: 5ç±» -> 4ç±»
        self.cfs_label_map = {
            0: 0,  # Wake -> Wake
            1: 1,  # NREM1 -> Light Sleep
            2: 1,  # NREM2 -> Light Sleep
            3: 2,  # NREM3 -> Deep Sleep
            4: 3,  # REM -> REM
        }

        self.file_sample_map = []
        failed_files = []

        total_samples = 0
        class_counts = np.zeros(4, dtype=np.int64)

        iterator = tqdm(npz_files, desc="åŠ è½½CFSæ•°æ®") if verbose else npz_files
        for npz_file in iterator:
            try:
                data = np.load(npz_file)
                y = data['y']

                for idx in range(len(y)):
                    original_label = int(y[idx])
                    if original_label in self.cfs_label_map:
                        new_label = self.cfs_label_map[original_label]
                        self.file_sample_map.append((npz_file, idx))
                        class_counts[new_label] += 1
                        total_samples += 1

                data.close()

            except Exception as e:
                failed_files.append((npz_file, str(e)))
                continue

        if verbose:
            if failed_files:
                print(f"\nâš ï¸  {len(failed_files)} ä¸ªæ–‡ä»¶åŠ è½½å¤±è´¥")

            print(f"\nâœ… CFSæµ‹è¯•æ•°æ®åŠ è½½å®Œæˆ:")
            print(f"   æ€»æ ·æœ¬æ•°: {total_samples:,}")
            print(f"   è¢«è¯•æ•°: {len(npz_files) - len(failed_files)}")

            class_names = ['Wake', 'Light Sleep', 'Deep Sleep', 'REM']
            print(f"\nğŸ“Š ç±»åˆ«åˆ†å¸ƒ:")
            for i, (name, count) in enumerate(zip(class_names, class_counts)):
                pct = count / total_samples * 100 if total_samples > 0 else 0
                print(f"   {i}: {name}: {count:,} ({pct:.1f}%)")

        self.class_counts = class_counts
        self.total_samples = total_samples

    def __getitem__(self, index):
        file_path, sample_idx = self.file_sample_map[index]

        data = np.load(file_path)
        x = data['x'][sample_idx]
        y = data['y'][sample_idx]
        data.close()

        original_label = int(y)
        y_label = self.cfs_label_map[original_label]

        x_tensor = torch.from_numpy(x.astype(np.float32)).unsqueeze(0)
        y_tensor = torch.tensor(y_label, dtype=torch.long)

        # Z-scoreæ ‡å‡†åŒ–
        x_tensor = (x_tensor - x_tensor.mean()) / (x_tensor.std() + 1e-8)

        return x_tensor, y_tensor

    def __len__(self):
        return len(self.file_sample_map)


# ============================================================================
# 3. è·¨æ•°æ®é›†è¯„ä¼°å‡½æ•°
# ============================================================================

def cross_dataset_evaluation(model_path, cfs_data_dir, output_dir, config):
    """
    ä½¿ç”¨MESAè®­ç»ƒçš„æ¨¡å‹åœ¨CFSæ•°æ®é›†ä¸Šè¿›è¡Œè¯„ä¼°
    """
    
    device = torch.device(f'cuda:{config["gpu_id"]}' if torch.cuda.is_available() else 'cpu')
    print(f"\nğŸ–¥ï¸  ä½¿ç”¨è®¾å¤‡: {device}")
    
    # ========== 1. åŠ è½½MESAè®­ç»ƒçš„æ¨¡å‹ ==========
    print(f"\nğŸ“¦ åŠ è½½MESAè®­ç»ƒçš„æ¨¡å‹: {model_path}")
    
    if not os.path.exists(model_path):
        raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
    
    model = AttnSleep4Class().to(device)
    
    # åŠ è½½æƒé‡
    state_dict = torch.load(model_path, map_location=device)
    model.load_state_dict(state_dict)
    model.eval()
    
    print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
    print(f"   å‚æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")
    
    # ========== 2. åŠ è½½CFSæµ‹è¯•æ•°æ® ==========
    print(f"\nğŸ“‚ åŠ è½½CFSæµ‹è¯•æ•°æ®: {cfs_data_dir}")
    
    npz_files = sorted(glob.glob(os.path.join(cfs_data_dir, '*.npz')))
    if len(npz_files) == 0:
        raise FileNotFoundError(f"æœªåœ¨ {cfs_data_dir} æ‰¾åˆ°NPZæ–‡ä»¶")
    
    print(f"   æ‰¾åˆ° {len(npz_files)} ä¸ªè¢«è¯•æ–‡ä»¶")
    
    # åˆ›å»ºæ•°æ®é›†å’ŒåŠ è½½å™¨
    test_dataset = CFSEEGTestDataset(npz_files, verbose=True)
    test_loader = DataLoader(
        test_dataset,
        batch_size=config['batch_size'],
        shuffle=False,
        num_workers=config['num_workers'],
        pin_memory=True
    )
    
    # ========== 3. åœ¨CFSä¸Šè¿›è¡Œæ¨ç† ==========
    print(f"\nğŸ§ª åœ¨CFSæ•°æ®é›†ä¸Šè¿›è¡Œæ¨ç†...")
    
    all_preds = []
    all_labels = []
    all_probs = []
    
    with torch.no_grad():
        for data, target in tqdm(test_loader, desc="æ¨ç†è¿›åº¦"):
            data = data.to(device)
            output = model(data)
            probs = torch.softmax(output, dim=1)
            _, predicted = torch.max(output.data, 1)
            
            all_preds.extend(predicted.cpu().numpy())
            all_labels.extend(target.numpy())
            all_probs.extend(probs.cpu().numpy())
    
    all_preds = np.array(all_preds)
    all_labels = np.array(all_labels)
    all_probs = np.array(all_probs)
    
    # ========== 4. è®¡ç®—è¯„ä¼°æŒ‡æ ‡ ==========
    print(f"\nğŸ“Š è®¡ç®—è¯„ä¼°æŒ‡æ ‡...")
    
    # åŸºæœ¬æŒ‡æ ‡
    accuracy = accuracy_score(all_labels, all_preds)
    kappa = cohen_kappa_score(all_labels, all_preds)
    f1_weighted = f1_score(all_labels, all_preds, average='weighted')
    f1_macro = f1_score(all_labels, all_preds, average='macro')
    
    # æ··æ·†çŸ©é˜µ
    cm = confusion_matrix(all_labels, all_preds)
    
    # æ¯ä¸ªç±»åˆ«çš„æŒ‡æ ‡
    class_names = ['Wake', 'Light', 'Deep', 'REM']
    report = classification_report(
        all_labels, all_preds, 
        target_names=class_names, 
        output_dict=True,
        zero_division=0
    )
    
    # ========== 5. æ‰“å°ç»“æœ ==========
    print(f"\n{'=' * 70}")
    print(f"è·¨æ•°æ®é›†è¯„ä¼°ç»“æœ: MESA â†’ CFS")
    print(f"{'=' * 70}")
    
    print(f"\nğŸ“ˆ æ•´ä½“æŒ‡æ ‡:")
    print(f"   å‡†ç¡®ç‡ (Accuracy): {accuracy * 100:.2f}%")
    print(f"   Cohen's Kappa: {kappa:.4f}")
    print(f"   F1 Score (weighted): {f1_weighted:.4f}")
    print(f"   F1 Score (macro): {f1_macro:.4f}")
    
    print(f"\nğŸ“Š æ¯ä¸ªç±»åˆ«çš„æ€§èƒ½:")
    print(f"{'ç±»åˆ«':<15} {'Precision':>10} {'Recall':>10} {'F1':>10} {'Support':>10}")
    print("-" * 55)
    for name in class_names:
        p = report[name]['precision']
        r = report[name]['recall']
        f = report[name]['f1-score']
        s = report[name]['support']
        print(f"{name:<15} {p:>10.3f} {r:>10.3f} {f:>10.3f} {int(s):>10}")
    
    print(f"\nåˆ†ç±»æŠ¥å‘Š:")
    print(classification_report(all_labels, all_preds, target_names=class_names, zero_division=0))
    
    # ========== 6. å¯è§†åŒ– ==========
    # æ··æ·†çŸ©é˜µ
    fig, axes = plt.subplots(1, 2, figsize=(16, 6))
    
    # ç»å¯¹æ•°å€¼
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=class_names, yticklabels=class_names, ax=axes[0])
    axes[0].set_title('Confusion Matrix (Counts)\nMESA â†’ CFS Cross-Dataset')
    axes[0].set_ylabel('True Label')
    axes[0].set_xlabel('Predicted Label')
    
    # å½’ä¸€åŒ– (æŒ‰è¡Œ)
    cm_normalized = cm.astype('float') / cm.sum(axis=1, keepdims=True)
    sns.heatmap(cm_normalized, annot=True, fmt='.2%', cmap='Blues',
                xticklabels=class_names, yticklabels=class_names, ax=axes[1])
    axes[1].set_title('Confusion Matrix (Normalized)\nMESA â†’ CFS Cross-Dataset')
    axes[1].set_ylabel('True Label')
    axes[1].set_xlabel('Predicted Label')
    
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, 'cross_dataset_confusion_matrix.png'), 
                dpi=150, bbox_inches='tight')
    plt.close()
    
    # æ¯ä¸ªç±»åˆ«çš„æ€§èƒ½æ¡å½¢å›¾
    fig, ax = plt.subplots(figsize=(10, 6))
    
    x = np.arange(len(class_names))
    width = 0.25
    
    precision = [report[name]['precision'] for name in class_names]
    recall = [report[name]['recall'] for name in class_names]
    f1_scores = [report[name]['f1-score'] for name in class_names]
    
    bars1 = ax.bar(x - width, precision, width, label='Precision', color='steelblue')
    bars2 = ax.bar(x, recall, width, label='Recall', color='coral')
    bars3 = ax.bar(x + width, f1_scores, width, label='F1-Score', color='seagreen')
    
    ax.set_ylabel('Score')
    ax.set_title('Per-Class Performance: MESA â†’ CFS Cross-Dataset')
    ax.set_xticks(x)
    ax.set_xticklabels(class_names)
    ax.legend()
    ax.set_ylim([0, 1])
    ax.grid(axis='y', alpha=0.3)
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for bars in [bars1, bars2, bars3]:
        for bar in bars:
            height = bar.get_height()
            ax.annotate(f'{height:.2f}',
                       xy=(bar.get_x() + bar.get_width() / 2, height),
                       xytext=(0, 3),
                       textcoords="offset points",
                       ha='center', va='bottom', fontsize=8)
    
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, 'cross_dataset_per_class_performance.png'), 
                dpi=150, bbox_inches='tight')
    plt.close()
    
    # ========== 7. ä¿å­˜ç»“æœ ==========
    results = {
        'experiment': 'Cross-Dataset Evaluation: MESA â†’ CFS',
        'model_path': model_path,
        'cfs_data_dir': cfs_data_dir,
        'n_subjects': len(npz_files),
        'n_samples': len(test_dataset),
        'metrics': {
            'accuracy': float(accuracy),
            'kappa': float(kappa),
            'f1_weighted': float(f1_weighted),
            'f1_macro': float(f1_macro)
        },
        'per_class_metrics': {
            name: {
                'precision': float(report[name]['precision']),
                'recall': float(report[name]['recall']),
                'f1': float(report[name]['f1-score']),
                'support': int(report[name]['support'])
            } for name in class_names
        },
        'confusion_matrix': cm.tolist(),
        'class_distribution': {
            name: int(test_dataset.class_counts[i]) 
            for i, name in enumerate(class_names)
        },
        'config': config,
        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    }
    
    results_path = os.path.join(output_dir, 'cross_dataset_results.json')
    with open(results_path, 'w') as f:
        json.dump(results, f, indent=2)
    
    print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {output_dir}")
    print(f"   - cross_dataset_results.json")
    print(f"   - cross_dataset_confusion_matrix.png")
    print(f"   - cross_dataset_per_class_performance.png")
    
    return results


# ============================================================================
# 4. ä¸»å‡½æ•°
# ============================================================================

def main():
    parser = argparse.ArgumentParser(description='Cross-Dataset Evaluation: MESA â†’ CFS')
    parser.add_argument('--model_path', type=str, required=True,
                        help='MESAè®­ç»ƒçš„æ¨¡å‹è·¯å¾„ (.pthæ–‡ä»¶)')
    parser.add_argument('--cfs_data_dir', type=str, required=True,
                        help='CFS EEG NPZæ–‡ä»¶ç›®å½•')
    parser.add_argument('--output_dir', type=str, default='./cross_dataset_results',
                        help='è¾“å‡ºç›®å½•')
    parser.add_argument('--batch_size', type=int, default=128,
                        help='Batch size')
    parser.add_argument('--gpu_id', type=int, default=0,
                        help='GPU ID')
    parser.add_argument('--num_workers', type=int, default=4,
                        help='æ•°æ®åŠ è½½workers')
    
    args = parser.parse_args()
    
    print("=" * 70)
    print("ğŸ”„ è·¨æ•°æ®é›†éªŒè¯: MESA â†’ CFS")
    print("=" * 70)
    print("\nè¿™ä¸ªå®éªŒéªŒè¯MESAè®­ç»ƒçš„æ¨¡å‹åœ¨CFSæ•°æ®é›†ä¸Šçš„æ³›åŒ–èƒ½åŠ›")
    
    # æ£€æŸ¥GPU
    if torch.cuda.is_available():
        print(f"\nâœ… CUDAå¯ç”¨")
        print(f"   ä½¿ç”¨GPU {args.gpu_id}: {torch.cuda.get_device_name(args.gpu_id)}")
    else:
        print("\nâš ï¸  CUDAä¸å¯ç”¨ï¼Œä½¿ç”¨CPU")
    
    # é…ç½®
    config = {
        'batch_size': args.batch_size,
        'gpu_id': args.gpu_id,
        'num_workers': args.num_workers
    }
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    output_dir = os.path.join(args.output_dir, f'mesa_to_cfs_{timestamp}')
    Path(output_dir).mkdir(parents=True, exist_ok=True)
    
    try:
        results = cross_dataset_evaluation(
            args.model_path,
            args.cfs_data_dir,
            output_dir,
            config
        )
        
        print(f"\n{'=' * 70}")
        print(f"ğŸ‰ è·¨æ•°æ®é›†è¯„ä¼°å®Œæˆ!")
        print(f"{'=' * 70}")
        print(f"\næœ€ç»ˆç»“æœ (MESAæ¨¡å‹ â†’ CFSæµ‹è¯•):")
        print(f"   å‡†ç¡®ç‡: {results['metrics']['accuracy'] * 100:.2f}%")
        print(f"   Kappa: {results['metrics']['kappa']:.4f}")
        print(f"   F1 (weighted): {results['metrics']['f1_weighted']:.4f}")
        
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return
    
    print("\n" + "=" * 70)
    print("âœ… å…¨éƒ¨å®Œæˆ!")
    print("=" * 70)


if __name__ == '__main__':
    main()
